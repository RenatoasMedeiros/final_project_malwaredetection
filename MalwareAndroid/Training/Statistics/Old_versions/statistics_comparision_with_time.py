import pandas as pd
import matplotlib.pyplot as plt
import os

# Function to process CSV files and extract median validation accuracy and loss for each optimizer
def process_csv(csv_files):
    median_metrics = {'val_accuracy': {}, 'val_loss': {}, 'total_time': {}}

    # Read and process each CSV file
    for csv_file in csv_files:
        optimizer_name = os.path.basename(csv_file).split('_')[-1].split('.')[0]
        df = pd.read_csv(csv_file)

        # Calculate median validation accuracy and loss across all folds and epochs
        median_val_accuracy = df.groupby('epoch')['val_accuracy'].median()
        median_val_loss = df.groupby('epoch')['val_loss'].median()

        # Calculate the total training time for each optimizer
        total_time = df.groupby('fold')['epoch_time'].sum().sum()

        median_metrics['val_accuracy'][optimizer_name] = median_val_accuracy
        median_metrics['val_loss'][optimizer_name] = median_val_loss
        median_metrics['total_time'][optimizer_name] = total_time

    return median_metrics

# Function to plot median validation accuracy and loss for each optimizer
def plot_median_metrics(median_metrics):
    # Plot median validation accuracy
    plt.figure(figsize=(10, 6))
    for optimizer_name, val_accuracy in median_metrics['val_accuracy'].items():
        plt.plot(val_accuracy.index, val_accuracy.values, label=optimizer_name)
    plt.xlabel('Epoch')
    plt.ylabel('Median Validation Accuracy')
    plt.title('Median Validation Accuracy Across Optimizers')
    plt.legend()
    plt.grid(True)
    plt.show()

    # Plot median validation loss
    plt.figure(figsize=(10, 6))
    for optimizer_name, val_loss in median_metrics['val_loss'].items():
        plt.plot(val_loss.index, val_loss.values, label=optimizer_name)
    plt.xlabel('Epoch')
    plt.ylabel('Median Validation Loss')
    plt.title('Median Validation Loss Across Optimizers')
    plt.legend()
    plt.grid(True)
    plt.show()

# Function to create a summary table comparing the performance of each optimizer
def create_summary_table(median_metrics):
    summary_data = []

    for optimizer_name in median_metrics['val_accuracy'].keys():
        median_accuracy = median_metrics['val_accuracy'][optimizer_name].median()
        median_loss = median_metrics['val_loss'][optimizer_name].median()
        total_time = median_metrics['total_time'][optimizer_name]

        summary_data.append({
            'Optimizer': optimizer_name,
            'Median Validation Accuracy': median_accuracy,
            'Median Validation Loss': median_loss,
            'Total Training Time': total_time
        })

    summary_df = pd.DataFrame(summary_data)
    return summary_df

# List of CSV files containing training data for different optimizers
csv_files = [
    'resnet50_crossval_history_model_not_pretrained_glorot_normal.csv',
    'resnet50_crossval_history_model_not_pretrained_glorot_uniform.csv',
    'resnet50_crossval_history_model_not_pretrained_lecun_normal.csv',
    'resnet50_crossval_history_model_not_pretrained_lecun_uniform.csv',
]

# Process CSV files and extract median validation accuracy and loss for each optimizer
median_metrics = process_csv(csv_files)

# Plot median validation accuracy and loss for each optimizer
plot_median_metrics(median_metrics)

# Create and display the summary table
summary_df = create_summary_table(median_metrics)
print(summary_df)
