 
# # TREINO COM RESNET E DATASET IMAGEM 64x64x3 V2 CROSS VALIDATION CALLBACKS


#Importar Bibliotecas
from keras.models import Sequential, load_model
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense, Rescaling, BatchNormalization
from keras.callbacks import ModelCheckpoint
from numpy import load
from tensorboard import version
import csv

import os, datetime
import numpy as np
from keras.preprocessing import image

import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay, accuracy_score
from sklearn.model_selection import KFold

import sklearn.datasets
import gc


#Verificar versão do TF e ver GPU
import tensorflow as tf
print(tf.__version__)


print("Num GPUs Available: ", len(tf.config.list_physical_devices('GPU')))
print("Num GPUs Available: ", len(tf.config.experimental.list_physical_devices('GPU')))

print("tensorboard.version.VERSION: ", version.VERSION)


directory='../Images/64x64'

train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    directory,
    label_mode='int',
    seed=1337,
    image_size=(64,64),
    batch_size= None,
)


image_array = []
label_array = []

for element in train_ds:  
    
    image_array.append(np.asarray(element[0]))
    label_array.append(np.asarray(element[1]))

image_array = np.asarray(image_array)
label_array = np.asarray(label_array)

print(image_array.shape)
print(label_array.shape)


x_train, x_test, y_train, y_test = train_test_split(image_array, label_array, test_size=0.1, random_state=42)

print(x_train.shape)
print(y_train.shape)
print(x_test.shape)
print(y_test.shape)

 
# ## MODELO 10


gc.collect()

# Define per-fold score containers
acc_eval_per_fold = []
loss_eval_per_fold = []
acc_per_fold = []
loss_per_fold = []
precision_per_fold = []
recall_per_fold = []
f1_score_per_fold = []
cm_score_per_fold = []
history_cv = []

with tf.device("/gpu:0"):
    # Define the K-fold Cross Validator
    kfold = KFold(n_splits=6, shuffle=True)

    # K-fold Cross Validation model evaluation
    fold_no = 1
    for train, test in kfold.split(x_train,y_train):

        # include_top=False => significa que somos nós a definir as camadas de inout e de output do modelo
        # pooling => Avg, Max, None
        pretrained_model=tf.keras.applications.ResNet50(include_top=False, weights='imagenet', input_tensor=None, 
                                                        input_shape=(64, 64, 3), pooling='Max', classes=5,classifier_activation="sigmoid")

        # False: mantem os pesos carregados, nao sao alterados ao longo do treino
        for layer in pretrained_model.layers:
            layer.trainable=True # False 

        # definição do modelo
        model=Sequential([ 
            pretrained_model,
            tf.keras.layers.Flatten(),
            tf.keras.layers.Dense(5, activation='softmax')
        ])

        model.compile(
            optimizer='adam',
            loss=tf.losses.SparseCategoricalCrossentropy(from_logits=False),
            metrics=['accuracy'])

        #Saved models path
        model_name = 'resnet50_crossval_64x64'
        save_path_best_model = '../Models/CrossValidation/ResNet50_64x64/' + model_name + '_fold_' + str(fold_no) +'.hdf5'

        # CREATE CALLBACKS
        checkpoint_val_acc = tf.keras.callbacks.ModelCheckpoint(save_path_best_model, 
                                                        monitor='val_accuracy', verbose=0, 
                                                        save_best_only=True, mode='max')


        callbacks_list = [checkpoint_val_acc]

        # Generate a print
        print('--------------------------------------------------------------------------------')
        print(f'Training for fold {fold_no} ...')


        # Fit data to model - uses x_train to train and validate
        history10 = model.fit(x_train[train], y_train[train],validation_data=(x_train[test], y_train[test]),
                                verbose=2, batch_size=16,callbacks=callbacks_list, epochs=50)

        gc.collect()

        history_cv.append(history10)

        #load best model from fold
        best_model = load_model(save_path_best_model)

        # Generate generalization metrics - uses x_test to validate and predict
        scores = best_model.evaluate(x_train[test], y_train[test], verbose=0)

        # Calculate predicted labels for the test set
        y_pred = np.argmax(best_model.predict(x_test), axis=-1)

        # Calculate precision, recall, and F1 score
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, average='macro')
        recall = recall_score(y_test, y_pred, average='macro')
        f1 = f1_score(y_test, y_pred, average='macro')
        cm = confusion_matrix(y_test, y_pred)

        print(f'Score for fold {fold_no}: {best_model.metrics_names[0]} of {round(scores[0],5)}; {best_model.metrics_names[1]} of {round(scores[1]*100,5)}%')

        # Append scores to the corresponding lists
        acc_eval_per_fold.append(scores[1] * 100)
        loss_eval_per_fold.append(scores[0])

        acc_per_fold.append(accuracy*100)
        precision_per_fold.append(precision*100)
        recall_per_fold.append(recall*100)
        f1_score_per_fold.append(f1*100)
        cm_score_per_fold.append(cm)

        # Increase fold number
        fold_no = fold_no + 1

        gc.collect()
    


# Print the precision, recall, and F1 score for each fold, as well as the average scores
print('Score per fold')
for i in range(len(acc_eval_per_fold)):
    print('------------------------------------------------------------------------')
    print(f'> Fold {i+1} -  Eval Loss: {round(loss_eval_per_fold[i],5)} - Eval Accuracy: {round(acc_eval_per_fold[i],5)}% - Accuracy: {round(acc_per_fold[i],5)}% - Precision: {round(precision_per_fold[i],5)}% - Recall: {round(recall_per_fold[i],5)}% - F1 Score: {round(f1_score_per_fold[i],5)}%')
print('------------------------------------------------------------------------')
print('Average scores for all folds:')
print(f'> Evaluation Accuracy: {round(np.mean(acc_eval_per_fold),5)} (+- {round(np.std(acc_per_fold),5)})')
print(f'> Evaluation Loss: {round(np.mean(loss_eval_per_fold),5)}')
print(f'> Accuracy: {round(np.mean(acc_per_fold),5)} (+- {round(np.std(acc_per_fold),5)})')
print(f'> Precision: {round(np.mean(precision_per_fold),5)} (+- {round(np.std(precision_per_fold),5)})')
print(f'> Recall: {round(np.mean(recall_per_fold),5)} (+- {round(np.std(recall_per_fold),5)})')
print(f'> F1 Score: {round(np.mean(f1_score_per_fold),5)} (+- {round(np.std(f1_score_per_fold),5)})')
print('------------------------------------------------------------------------')



csv_file_path = "resnet50_crossval_sigmoid_model_history.csv"
# Open the CSV file in append mode
with open(csv_file_path, mode='w', newline='') as file:
    writer = csv.writer(file)
    
    # Write the header
    writer.writerow(['fold', 'epoch', 'train_accuracy', 'train_loss', 'val_accuracy', 'val_loss'])
    
    # Iterate over all folds
    for i in range(6):
        fold = i + 1  # fold number
        train_acc = history_cv[i].history['accuracy']
        train_loss = history_cv[i].history['loss']
        val_acc = history_cv[i].history['val_accuracy']
        val_loss = history_cv[i].history['val_loss']
        
        # Write the data for each epoch in the fold
        for epoch in range(len(train_acc)):
            writer.writerow([fold, epoch + 1, train_acc[epoch], train_loss[epoch], val_acc[epoch], val_loss[epoch]])

print("History data for all folds saved to:", csv_file_path)