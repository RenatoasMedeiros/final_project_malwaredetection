 
# # TREINO COM RESNET E DATASET IMAGEM 64x64x3 V2 CROSS VALIDATION CALLBACKS


#Importar Bibliotecas
from keras.models import Sequential, load_model
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense, Rescaling, BatchNormalization
from keras.callbacks import ModelCheckpoint
from numpy import load
from tensorboard import version
import csv

import os, datetime
import numpy as np
from keras.preprocessing import image

import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay, accuracy_score
from sklearn.model_selection import KFold

import sklearn.datasets
import gc


#Verificar versÃ£o do TF e ver GPU
import tensorflow as tf
print(tf.__version__)


print("Num GPUs Available: ", len(tf.config.list_physical_devices('GPU')))
print("Num GPUs Available: ", len(tf.config.experimental.list_physical_devices('GPU')))

print("tensorboard.version.VERSION: ", version.VERSION)


directory='../Images/64x64'

train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    directory,
    label_mode='int',
    seed=1337,
    image_size=(64,64),
    batch_size= None,
)


image_array = []
label_array = []

for element in train_ds:  
    
    image_array.append(np.asarray(element[0]))
    label_array.append(np.asarray(element[1]))

image_array = np.asarray(image_array)
label_array = np.asarray(label_array)

print(image_array.shape)
print(label_array.shape)


x_train, x_test, y_train, y_test = train_test_split(image_array, label_array, test_size=0.1, random_state=42)

print(x_train.shape)
print(y_train.shape)
print(x_test.shape)
print(y_test.shape)

 
# ## MODELO 10


gc.collect()

# Define per-fold score containers
acc_eval_per_fold = []
loss_eval_per_fold = []
acc_per_fold = []
loss_per_fold = []
precision_per_fold = []
recall_per_fold = []
f1_score_per_fold = []
cm_score_per_fold = []

weight_initializers = [
    'constant', 
    'glorot_normal', 
    'glorot_uniform', 
    'he_normal', 
    'he_uniform',
    'identity', 
    'lecun_normal', 
    'lecun_uniform', 
    'ones', 
    'orthogonal',
    'random_normal', 
    'random_uniform', 
    'truncated_normal', 
    'variance_scaling', 
    'zeros'
]

# Save data to CSV
csv_file_path = "resnet50_crossval_history_model_weights.csv"


# Open the CSV file in append mode
with open(csv_file_path, mode='a', newline='') as file:
    writer = csv.writer(file)

    # Write the header only if the file is empty
    if os.path.getsize(self.csv_file_path) == 0:
        writer.writerow(['fold', 'initializer', 'epoch', 'train_accuracy', 'train_loss', 'val_accuracy', 'val_loss'])

    # Define the K-fold Cross Validator
    kfold = KFold(n_splits=5, shuffle=True)

    for weight_initializer in weight_initializers:
        # K-fold Cross Validation model evaluation
        fold_no = 1
        for train, test in kfold.split(x_train, y_train):
            # Define pretrained model
            pretrained_model = tf.keras.applications.ResNet50(include_top=False, weights='imagenet', input_tensor=None,
                                        input_shape=(64, 64, 3), pooling='Max')

            # Manter a True para alterar os pesos
            for layer in pretrained_model.layers:
                layer.trainable = True

            # Define model
            model = Sequential([
                pretrained_model,
                tf.keras.layers.Flatten(),
                tf.keras.layers.Dense(5, activation='softmax', kernel_initializer=weight_initializer)
            ])

            model.compile(
                optimizer='adam',
                loss=tf.losses.SparseCategoricalCrossentropy(from_logits=False),
                metrics=['accuracy'])

            # Saved models path
            model_name = 'resnet50_crossval_64x64_' + weight_initializer
            save_path_best_model = '../Models/CrossValidation/ResNet50_64x64/' + model_name + '_fold_' + str(
                fold_no) + '.hdf5'
            
            # Print information
            print('--------------------------------------------------------------------------------')
            print(f'Training for fold {fold_no} with weight initializer: {weight_initializer} ...')

            # Fit data to model
            history = model.fit(x_train[train], y_train[train], validation_data=(x_train[test], y_train[test]),
                                verbose=2, batch_size=16, epochs=50)

            # Write the data for each epoch to the CSV file
            for epoch, (train_acc, train_loss, val_acc, val_loss) in enumerate(zip(history.history['accuracy'],
                                                                                   history.history['loss'],
                                                                                   history.history['val_accuracy'],
                                                                                   history.history['val_loss'])):
                writer.writerow([fold_no, weight_initializer, epoch + 1, train_acc, train_loss, val_acc, val_loss])
                file.flush()  # Flush the buffer after writing each row

            # Load best model
            best_model = load_model(save_path_best_model)

            # Evaluate model
            scores = best_model.evaluate(x_train[test], y_train[test], verbose=0)

            # Append scores to lists
            acc_eval_per_fold.append(scores[1] * 100)
            loss_eval_per_fold.append(scores[0])

            # Increment fold number
            fold_no += 1

# Print the precision, recall, and F1 score for each fold, as well as the average scores
print('Score per fold')
for i in range(len(acc_eval_per_fold)):
    print('------------------------------------------------------------------------')
    print(f'> Fold {i+1} -  Eval Loss: {round(loss_eval_per_fold[i],5)} - Eval Accuracy: {round(acc_eval_per_fold[i],5)}% - Accuracy: {round(acc_per_fold[i],5)}% - Precision: {round(precision_per_fold[i],5)}% - Recall: {round(recall_per_fold[i],5)}% - F1 Score: {round(f1_score_per_fold[i],5)}%')
print('------------------------------------------------------------------------')
print('Average scores for all folds:')
print(f'> Evaluation Accuracy: {round(np.mean(acc_eval_per_fold),5)} (+- {round(np.std(acc_per_fold),5)})')
print(f'> Evaluation Loss: {round(np.mean(loss_eval_per_fold),5)}')
print(f'> Accuracy: {round(np.mean(acc_per_fold),5)} (+- {round(np.std(acc_per_fold),5)})')
print(f'> Precision: {round(np.mean(precision_per_fold),5)} (+- {round(np.std(precision_per_fold),5)})')
print(f'> Recall: {round(np.mean(recall_per_fold),5)} (+- {round(np.std(recall_per_fold),5)})')
print(f'> F1 Score: {round(np.mean(f1_score_per_fold),5)} (+- {round(np.std(f1_score_per_fold),5)})')
print('------------------------------------------------------------------------')

print("History data for all folds saved to:", csv_file_path)