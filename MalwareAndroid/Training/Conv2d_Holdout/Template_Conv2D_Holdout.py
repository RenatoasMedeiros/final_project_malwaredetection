


#Importar Bibliotecas
import os
import datetime
import numpy as np
import csv
import tensorflow as tf
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Rescaling, Dropout
from tensorflow.keras.callbacks import ModelCheckpoint
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix
from sklearn.model_selection import train_test_split
from keras.preprocessing import image
from keras.callbacks import Callback
import keras.backend as K
import gc
import time



#Verificar versÃ£o do TF e ver GPU

print(tf.__version__)


print("Num GPUs Available: ", len(tf.config.list_physical_devices('GPU')))
print("Num GPUs Available: ", len(tf.config.experimental.list_physical_devices('GPU')))



directory = '../Images/64x64'

train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    directory,
    label_mode='int',
    seed=1337,
    image_size=(64, 64),
    batch_size=None,
)

image_array = []
label_array = []

for element in train_ds:
    image_array.append(np.asarray(element[0]))
    label_array.append(np.asarray(element[1]))

image_array = np.asarray(image_array)
label_array = np.asarray(label_array)

model_x_train, model_x_val, model_y_train, model_y_val = train_test_split(image_array, label_array,
                                                                          test_size=0.2, random_state=42)

model_x_val, model_x_test, model_y_val, model_y_test = train_test_split(model_x_val, model_y_val, test_size=0.2)

print('Data for training:')
print(model_x_train.shape)
print(model_y_train.shape)

print('Data for validation:')
print(model_x_val.shape)
print(model_y_val.shape)

print('Data for testing:')
print(model_x_test.shape)
print(model_y_test.shape)

class CustomCallback(Callback):
    def __init__(self, csv_file_path):
        super(CustomCallback, self).__init__()
        self.start_time = None
        self.csv_file_path = csv_file_path

    def on_train_begin(self, logs=None):
        self.start_time = time.time()

    def on_epoch_end(self, epoch, logs=None):
        with open(self.csv_file_path, mode='a', newline='') as file:
            writer = csv.writer(file)
            if os.path.getsize(self.csv_file_path) == 0:
                writer.writerow(['epoch', 'train_accuracy', 'train_loss',
                                 'val_accuracy', 'val_loss', 'epoch_time',
                                 'val_precision', 'val_recall', 'val_f1'])
            writer_csv = csv.writer(file)

            train_acc = logs.get('accuracy')
            train_loss = logs.get('loss')
            val_acc = logs.get('val_accuracy')
            val_loss = logs.get('val_loss')
            epoch_time = time.time() - self.start_time

            y_pred_val = np.argmax(model.predict(model_x_test), axis=-1)
            val_precision = precision_score(model_y_test, y_pred_val, average='macro')
            val_recall = recall_score(model_y_test, y_pred_val, average='macro')
            val_f1 = f1_score(model_y_test, y_pred_val, average='macro')

            writer_csv.writerow([epoch + 1, train_acc, train_loss,
                                 val_acc, val_loss, epoch_time, val_precision, val_recall, val_f1])


 
# ## MODELO


model = Sequential()
model.add(Rescaling(1./127.5, offset=-1, input_shape=(64, 64, 3)))
model.add(Conv2D(filters=128, kernel_size=(2), strides=(1), activation='relu'))
model.add(MaxPooling2D(pool_size=(2), padding='valid', strides=(1)))
model.add(Dropout(0.3))
model.add(Conv2D(filters=128, kernel_size=(2), strides=(1), activation='relu'))
model.add(MaxPooling2D(pool_size=(2), padding='valid', strides=(1)))
model.add(Dropout(0.3))
model.add(Conv2D(filters=128, kernel_size=(2), strides=(1), activation='relu'))
model.add(MaxPooling2D(pool_size=(2), padding='valid', strides=(1)))
model.add(Dropout(0.3))
model.add(Conv2D(filters=128, kernel_size=(2), strides=(1), activation='relu'))
model.add(MaxPooling2D(pool_size=(2), padding='valid', strides=(1)))
model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(5, activation='softmax'))

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model_name = 'conv2D_holdout_64x64_TUNADO'
save_path_best_model = '../Models/Holdout/Conv2D_64x64/' + model_name + '.keras'

checkpoint_val_acc = ModelCheckpoint(save_path_best_model, 
                                    monitor='val_accuracy', verbose=0, 
                                    save_best_only=True, mode='max')

callbacks_list = [checkpoint_val_acc, CustomCallback("logs/Template_Holdout_tunado.csv")]

model.summary()

history = model.fit(model_x_train, model_y_train,
                    validation_data=(model_x_val, model_y_val),
                    epochs=50,
                    verbose=2,
                    batch_size=64,
                    callbacks=callbacks_list)

best_model_holdout = load_model(save_path_best_model)

model_scores = best_model_holdout.evaluate(model_x_val, model_y_val, verbose=0)

model_y_pred = np.argmax(best_model_holdout.predict(model_x_test), axis=-1)

model_accuracy = accuracy_score(model_y_test, model_y_pred)
model_precision = precision_score(model_y_test, model_y_pred, average='macro')
model_recall = recall_score(model_y_test, model_y_pred, average='macro')
model_f1 = f1_score(model_y_test, model_y_pred, average='macro')
model_cm = confusion_matrix(model_y_test, model_y_pred)

print(f'Score: Eval {model.metrics_names[0]} of {round(model_scores[0], 5)}; Eval {model.metrics_names[1]} of {round(model_scores[1]*100, 5)}%')
print(f'> Accuracy: {round(model_accuracy*100, 5)}%')
print(f'> Precision: {round(model_precision*100, 5)}%')
print(f'> Recall: {round(model_recall*100, 5)}%')
print(f'> F1 Score: {round(model_f1*100, 5)}%')
